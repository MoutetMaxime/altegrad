{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2024<br>Transfer learning for NLP</h2>\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        \"\"\"\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         \"\"\"\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid)  # nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout=dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            nhid, nhead, dim_feedforward=nhid, dropout=dropout\n",
        "        )  # We assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, mask=src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout=dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhb2gkUhJMR0",
        "outputId": "8ea0c463-7b13-4fc5-99a7-816be43258e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100  # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape)\n",
        "\n",
        "# The shape here is (batch_size, len(sequence), ntokens)\n",
        "# Indeed, if we only considered the classification task, we would have only (batch_size, ntokens)\n",
        "# But as we consider the language modeling task, we want for each token the probability of the next token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhdS5u1lYMnc",
        "outputId": "f34aad70-ce42-4bd8-a13e-927654d79b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------+------------+\n",
            "|                           Modules                           | Parameters |\n",
            "+-------------------------------------------------------------+------------+\n",
            "|                     base.encoder.weight                     |   20000    |\n",
            "|  base.transformer_encoder.layers.0.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.0.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.0.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.0.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.0.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.0.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.0.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.0.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.0.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.0.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.0.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.0.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.1.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.1.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.1.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.1.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.1.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.1.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.1.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.1.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.1.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.1.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.1.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.1.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.2.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.2.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.2.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.2.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.2.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.2.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.2.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.2.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.2.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.2.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.2.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.2.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.3.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.3.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.3.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.3.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.3.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.3.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.3.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.3.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.3.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.3.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.3.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.3.norm2.bias        |    200     |\n",
            "|                  classifier.decoder.weight                  |   20000    |\n",
            "|                   classifier.decoder.bias                   |    100     |\n",
            "+-------------------------------------------------------------+------------+\n",
            "Total Trainable Params: 1008100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1008100"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params += param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjd26ghWuff",
        "outputId": "d5752c70-c803-4fe7-8dc6-a44f71152371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-21 14:11:53--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.2’\n",
            "\n",
            "\rdict.txt.2            0%[                    ]       0  --.-KB/s               \rdict.txt.2          100%[===================>] 564.05K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-10-21 14:11:53 (11.7 MB/s) - ‘dict.txt.2’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdH_-JeFbGA",
        "outputId": "9567ef9d-8640-41b4-b8df-0bd17157bd7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\n",
        "    \"<sos>\": 0,\n",
        "    \"<pad>\": 1,\n",
        "    \"<eos>\": 2,\n",
        "    \"<oov>\": 3,\n",
        "}  # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx + 4\n",
        "\n",
        "ind2token = {ind: token for token, ind in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            (\n",
        "                self.token2ind[token]\n",
        "                if token in self.token2ind\n",
        "                else self.token2ind[\"<oov>\"]\n",
        "            )\n",
        "            for token in sequence[: self.max_len]\n",
        "        ]\n",
        "\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        # we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch],\n",
        "        padding_value=token2ind[\"<pad>\"],\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=max_len,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(ind2token)  # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2  # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind[\"<pad>\"])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader):  # step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask)  # step 2\n",
        "        if task == \"classification\":\n",
        "            # last vector only\n",
        "            output = output[-1]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1]\n",
        "        target = target.to(device)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        # step 3\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model.parameters(), 0.5\n",
        "        )  # prevent exploding gradient\n",
        "        # step 4\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch,\n",
        "                    idx,\n",
        "                    len(data_loader),\n",
        "                    cur_loss,\n",
        "                    math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwh3n9xZQy4e",
        "outputId": "487e305a-b01f-4a48-ed36-56ce440c4ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-21 14:12:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.3’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-10-21 14:12:15 (101 MB/s) - ‘pretraining_subset.txt.3’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m11g4ScjZaR",
        "outputId": "6e8adb7f-ccb8-45ef-b929-d939ab0d61e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.31804 | ppl 1507.245\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.49649 | ppl  662.811\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.20549 | ppl  495.461\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.04590 | ppl  422.379\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.92251 | ppl  373.349\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.84074 | ppl  344.035\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.50158 | ppl  245.079\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.49181 | ppl  242.696\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.44327 | ppl  231.197\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.40605 | ppl  222.751\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.38973 | ppl  219.145\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.35713 | ppl  212.115\n"
          ]
        }
      ],
      "source": [
        "# pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1):  # 5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BcBC6FSkMH3",
        "outputId": "34380c10-ab91-45ac-ffc8-897fabc7e59a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-21 14:27:38--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.1’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   251MB/s    in 0.3s    \n",
            "\n",
            "2024-10-21 14:27:38 (251 MB/s) - ‘pretrained_model_4layers.pt.1’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "<ipython-input-42-76a40ce8b80e>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('pretrained_model_4layers.pt')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBRRVsWqlIoQ",
        "outputId": "67d92b2b-a6a8-44a4-b93d-f4884fbeeb3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "--2024-10-21 14:27:44--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.1’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-10-21 14:27:44 (18.1 MB/s) - ‘sentencepiece.french.model.1’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "# !pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind[\"<sos>\"]] + [\n",
        "        token2ind[el] for el in sent_pieces\n",
        "    ]  # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = torch.argmax(out[-1], axis=1)\n",
        "    next_token_ind = next_token_ind.item()\n",
        "    return next_token_ind, out\n",
        "\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    if len(sent.split()) > max_len:\n",
        "        raise ValueError(\"Sentence too long\")\n",
        "\n",
        "    for i in range(max_len - len(sent.split())):\n",
        "        next_token_ind, out = infer_next_token(sent)\n",
        "\n",
        "        if next_token_ind == token2ind[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "        next_token = ind2token[next_token_ind]\n",
        "        sent = sent + \" \" + s.decode_pieces([next_token])\n",
        "\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f83Nn5nSly4v",
        "outputId": "1988bf34-e3fc-439f-96bd-cdac2cb10db5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques .'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1BZsblmEmx",
        "outputId": "7f25d3fc-1cc2-44d1-fb00-34e16df3c841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-21 14:32:22--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-10-21 14:32:22 (21.5 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2024-10-21 14:32:22--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-21 14:32:23 (44.7 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2024-10-21 14:32:23--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-10-21 14:32:23 (26.1 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2024-10-21 14:32:23--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-21 14:32:23 (61.3 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    model.eval()\n",
        "    total_acc, total_length = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(data_loader):\n",
        "            input = data[0].to(device)\n",
        "\n",
        "            src_mask = model.base.generate_square_subsequent_mask(input.size(0)).to(\n",
        "                device\n",
        "            )\n",
        "            output = model(input, src_mask)\n",
        "            output = output[-1]\n",
        "\n",
        "            target = data[1].to(device)\n",
        "\n",
        "            total_length += len(target)\n",
        "            total_acc += (torch.argmax(output, dim=1) == target).sum().item()\n",
        "\n",
        "    total_acc = total_acc / total_length\n",
        "    return total_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "# save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save(\n",
        "    {\n",
        "        \"model_state_dict\": model.base.state_dict(),\n",
        "    },\n",
        "    \"pretrained_model_4layers_no_class_head.pt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-xclMCpnVpw",
        "outputId": "76cabce2-0eb0-4d0f-870e-bf7010a9e34c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.76768 | ppl    2.155\n",
            "| epoch   1 |   100/  200 steps | loss 0.72838 | ppl    2.072\n",
            "| epoch   1 |   150/  200 steps | loss 0.70951 | ppl    2.033\n",
            "| epoch   2 |    50/  200 steps | loss 0.64948 | ppl    1.915\n",
            "| epoch   2 |   100/  200 steps | loss 0.62927 | ppl    1.876\n",
            "| epoch   2 |   150/  200 steps | loss 0.55868 | ppl    1.748\n",
            "| epoch   3 |    50/  200 steps | loss 0.45549 | ppl    1.577\n",
            "| epoch   3 |   100/  200 steps | loss 0.42905 | ppl    1.536\n",
            "| epoch   3 |   150/  200 steps | loss 0.42981 | ppl    1.537\n",
            "| epoch   4 |    50/  200 steps | loss 0.18519 | ppl    1.203\n",
            "| epoch   4 |   100/  200 steps | loss 0.20065 | ppl    1.222\n",
            "| epoch   4 |   150/  200 steps | loss 0.14038 | ppl    1.151\n",
            "| epoch   5 |    50/  200 steps | loss 0.06868 | ppl    1.071\n",
            "| epoch   5 |   100/  200 steps | loss 0.03952 | ppl    1.040\n",
            "| epoch   5 |   150/  200 steps | loss 0.04795 | ppl    1.049\n",
            "| epoch   6 |    50/  200 steps | loss 0.00164 | ppl    1.002\n",
            "| epoch   6 |   100/  200 steps | loss 0.01328 | ppl    1.013\n",
            "| epoch   6 |   150/  200 steps | loss 0.00013 | ppl    1.000\n",
            "| epoch   7 |    50/  200 steps | loss 0.00169 | ppl    1.002\n",
            "| epoch   7 |   100/  200 steps | loss 0.00399 | ppl    1.004\n",
            "| epoch   7 |   150/  200 steps | loss 0.00008 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00116 | ppl    1.001\n",
            "| epoch   8 |   150/  200 steps | loss 0.00014 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-68-f09076582a3e>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |    50/  200 steps | loss 0.08126 | ppl    1.085\n",
            "| epoch   1 |   100/  200 steps | loss 0.08170 | ppl    1.085\n",
            "| epoch   1 |   150/  200 steps | loss 0.00359 | ppl    1.004\n",
            "| epoch   2 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   2 |   100/  200 steps | loss 0.00359 | ppl    1.004\n",
            "| epoch   2 |   150/  200 steps | loss 0.03000 | ppl    1.030\n",
            "| epoch   3 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   3 |   100/  200 steps | loss 0.00180 | ppl    1.002\n",
            "| epoch   3 |   150/  200 steps | loss 0.02008 | ppl    1.020\n",
            "| epoch   4 |    50/  200 steps | loss 0.00040 | ppl    1.000\n",
            "| epoch   4 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   4 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |    50/  200 steps | loss 0.04469 | ppl    1.046\n",
            "| epoch   5 |   100/  200 steps | loss 0.00042 | ppl    1.000\n",
            "| epoch   5 |   150/  200 steps | loss 0.00555 | ppl    1.006\n",
            "| epoch   6 |    50/  200 steps | loss 0.07535 | ppl    1.078\n",
            "| epoch   6 |   100/  200 steps | loss 0.04069 | ppl    1.042\n",
            "| epoch   6 |   150/  200 steps | loss 0.04483 | ppl    1.046\n",
            "| epoch   7 |    50/  200 steps | loss 0.00095 | ppl    1.001\n",
            "| epoch   7 |   100/  200 steps | loss 0.00129 | ppl    1.001\n",
            "| epoch   7 |   150/  200 steps | loss 0.01057 | ppl    1.011\n",
            "| epoch   8 |    50/  200 steps | loss 0.02554 | ppl    1.026\n",
            "| epoch   8 |   100/  200 steps | loss 0.00195 | ppl    1.002\n",
            "| epoch   8 |   150/  200 steps | loss 0.00060 | ppl    1.001\n",
            "| epoch   9 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00080 | ppl    1.001\n",
            "| epoch   9 |   150/  200 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.04686 | ppl    1.048\n",
            "| epoch  10 |   100/  200 steps | loss 0.04833 | ppl    1.050\n",
            "| epoch  10 |   150/  200 steps | loss 0.02758 | ppl    1.028\n",
            "| epoch  11 |    50/  200 steps | loss 0.06449 | ppl    1.067\n",
            "| epoch  11 |   100/  200 steps | loss 0.00244 | ppl    1.002\n",
            "| epoch  11 |   150/  200 steps | loss 0.00595 | ppl    1.006\n",
            "| epoch  12 |    50/  200 steps | loss 0.00746 | ppl    1.007\n",
            "| epoch  12 |   100/  200 steps | loss 0.00287 | ppl    1.003\n",
            "| epoch  12 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.01854 | ppl    1.019\n",
            "| epoch  13 |   100/  200 steps | loss 0.03244 | ppl    1.033\n",
            "| epoch  13 |   150/  200 steps | loss 0.03241 | ppl    1.033\n",
            "| epoch  14 |    50/  200 steps | loss 0.00140 | ppl    1.001\n",
            "| epoch  14 |   100/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.10461 | ppl    1.110\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        # load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        # load state dict\n",
        "        model.base.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task=\"classification\",\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task=\"classification\",\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "RCpBIdTHojm6",
        "outputId": "83467eaf-9cf7-4907-b9a8-ac7747fb943b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(pretrained_valid_acc, \"c\", label=\"Pretrained accuracy\")\n",
        "plt.plot(from_scratch_valid_acc, \"m\", label=\"From scratch accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
